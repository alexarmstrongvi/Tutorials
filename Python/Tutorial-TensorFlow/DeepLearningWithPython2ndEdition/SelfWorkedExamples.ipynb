{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a542a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ffa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence wanring about recompiling tensorflow to use more optimal CPU instructions\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ae9815",
   "metadata": {},
   "source": [
    "## 2.1 A first look at a neural network\n",
    "Creating, training, and evaluation a simple NN on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db115b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2157caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = train\n",
    "test_images, test_labels = test\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(np.unique(train_labels))\n",
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169470f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(2**9, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss      = 'sparse_categorical_crossentropy',\n",
    "              metrics   = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "UINT8_MAX = 2**8 - 1\n",
    "def prepare_images(t):\n",
    "    return t.reshape((-1,28*28)).astype('float32') / UINT8_MAX\n",
    "\n",
    "if train_images.ndim == 3:\n",
    "    print(train_images.shape)\n",
    "    train_images = prepare_images(train_images)\n",
    "    test_images = prepare_images(test_images)\n",
    "print(train_images.shape, test_images.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=2**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "true = test_labels[idx]\n",
    "pred_probs = model.predict(test_images[idx:idx+1])\n",
    "pred = pred_probs.argmax()\n",
    "prob = pred_probs[0,pred]\n",
    "print(f'True = {true}; Pred = {pred} ({prob:.5%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e95476",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, test_labels., verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d665b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = results\n",
    "print(f'Loss = {loss}')\n",
    "print(f'Acc = {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c345e3e",
   "metadata": {},
   "source": [
    "## 2.5 Build the NN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b3c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab1def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer: __init__, __call__\n",
    "class NaiveDense():\n",
    "    def __init__(self, units, activation=None):\n",
    "        self.activation = activation\n",
    "        self.units  = units\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        if self.w is None or self.b is None:\n",
    "            w_shape = (inputs.shape[-1], self.units)\n",
    "            self.w = tf.random.uniform(w_shape, 0, 1e-1)\n",
    "            self.w = tf.Variable(self.w)\n",
    "\n",
    "            b_shape = (self.units,)\n",
    "            self.b = tf.zeros(b_shape)\n",
    "            self.b = tf.Variable(self.b)\n",
    "        return self.activation(inputs @ self.w + self.b)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.w, self.b]\n",
    "\n",
    "class NaiveSequential():\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.learning_rate = 1e-3\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights\n",
    "\n",
    "    def fit(self, inputs, labels, epochs, batch_size):\n",
    "        for epoch in range(epochs):\n",
    "            print(f'Start of Epoch {epoch}')\n",
    "            for x, y_true in batches(inputs, labels, batch_size):\n",
    "                loss = self.update_weights(x, y_true)\n",
    "            print(f'End of Epoch {epoch}; loss = {loss:.3f}')\n",
    "    \n",
    "    def update_weights(self, x, y_true):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            #print(f'DEBUG :: 2) y_pred.shape={y_pred.shape}; y_true.dtype={y_true.shape}')\n",
    "            loss = tf.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "            avg_loss = tf.reduce_mean(loss)\n",
    "        gradients = tape.gradient(avg_loss, self.weights)\n",
    "        \n",
    "        for g, w in zip(gradients, self.weights):\n",
    "            w.assign_sub(g * self.learning_rate)\n",
    "        \n",
    "        return avg_loss\n",
    "\n",
    "def batches(inputs, labels, batch_size):\n",
    "    start = 0\n",
    "    while start < len(inputs):\n",
    "        stop = min(len(inputs), start + batch_size)\n",
    "        yield inputs[start:stop], labels[start:stop]\n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c27b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveSequential([ \n",
    "    NaiveDense(2**9, activation=tf.nn.relu),\n",
    "    NaiveDense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=2**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a98e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(test_images).numpy()\n",
    "acc = (y_pred.argmax(axis=1) == test_labels).mean()\n",
    "print(f'Accuracy : {acc:.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc33fa",
   "metadata": {},
   "source": [
    "## 3.5.4 Building a linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda365ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "n_samples = 1000\n",
    "\n",
    "x_train1 = np.random.multivariate_normal(mean=[3,0], cov=[[1,0.5],[0.5,1]], size=n_samples).astype(np.float32)\n",
    "x_train2 = np.random.multivariate_normal(mean=[0,3], cov=[[1,0.5],[0.5,1]], size=n_samples).astype(np.float32)\n",
    "x_train = tf.concat([x_train1, x_train2], axis=0)\n",
    "y_train = tf.concat([tf.ones((n_samples,1)), tf.zeros((n_samples,1))], axis=0)\n",
    "\n",
    "input_dim = x_train.shape[-1]\n",
    "output_dim = y_train.shape[-1]\n",
    "w_init = tf.random.uniform(shape=(input_dim, output_dim))\n",
    "b_init = tf.random.uniform(shape=(output_dim,))\n",
    "w = tf.Variable(initial_value=w_init, name='slope')\n",
    "b = tf.Variable(initial_value=b_init, name='bias')\n",
    "trainable_weights = [w, b]\n",
    "\n",
    "def model(x: tf.Tensor) -> tf.Tensor:\n",
    "    return x @ w + b\n",
    "\n",
    "def compute_loss(y_pred: tf.Tensor, y_true: tf.Tensor) -> float:\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "def train_step(x: tf.Tensor, y_true: tf.Tensor) -> float:\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss = compute_loss(y_pred, y_true)\n",
    "    grads = tape.gradient(loss, trainable_weights)\n",
    "    for grad, weight in zip(grads, trainable_weights):\n",
    "        weight.assign_sub(grad * learning_rate)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def plot(x_train, y_train, w, b):\n",
    "    x = x_train[:,0]\n",
    "    y = x_train[:,1]\n",
    "    c = y_train[:,0]\n",
    "    plt.scatter(x, y, c=c)\n",
    "\n",
    "    slope = -w[0]/w[1]\n",
    "    intercept = (0.5-b)/w[1]\n",
    "    x_line = np.linspace(tf.reduce_min(x), tf.reduce_max(x))\n",
    "    y_line = slope * x_line + intercept\n",
    "    plt.plot(x_line, y_line, \"-r\")\n",
    "\n",
    "plot(x_train, y_train, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b687f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_steps = 40\n",
    "loss_init = None\n",
    "for s in range(n_train_steps):\n",
    "    loss = train_step(x_train, y_train)\n",
    "    if loss_init is None:\n",
    "        loss_init = loss\n",
    "print(f'Loss : {loss_init} -> {loss}')\n",
    "plot(x_train, y_train, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf2c927",
   "metadata": {},
   "source": [
    "## 3.6.1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5eceb",
   "metadata": {},
   "source": [
    "## Model/Layer subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f07dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "969c646c",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3c920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5a2bf2b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f14f8ff64e7e20920c965de8568c02bf9400c39d1db507b36ea4a076fec4b4c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
